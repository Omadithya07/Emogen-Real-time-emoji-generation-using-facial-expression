{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yudF5sZwHI08"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import seaborn as sb\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cFnv4-5BJJyO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The data set has been extracted.\n"
          ]
        }
      ],
      "source": [
        "# Extracting the compressed dataset.\n",
        "from zipfile import ZipFile\n",
        "data_path = 'fer2013.zip'\n",
        "\n",
        "with ZipFile(data_path,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The data set has been extracted.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WIUrGD05JNWe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = 'train'\n",
        "classes = os.listdir(path)\n",
        "classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rR-QY_3xJPwm"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "count = []\n",
        "for cat in classes:\n",
        "\tcount.append(len(os.listdir(f'{path}/{cat}')))\n",
        "sb.barplot(x=classes,y=count)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0ojK7dTeJhlS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "\t\t'train',\n",
        "\t\ttarget_size=(48,48),\n",
        "\t\tbatch_size=64,\n",
        "\t\tcolor_mode=\"grayscale\",\n",
        "\t\tclass_mode='categorical')\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "\t\t'test',\n",
        "\t\ttarget_size=(48,48),\n",
        "\t\tbatch_size=64,\n",
        "\t\tcolor_mode=\"grayscale\",\n",
        "\t\tclass_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5rcO8S7bJlXv"
      },
      "outputs": [],
      "source": [
        "emotions = list(train_gen.class_indices.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r_84WSKLJnbC"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "\t\t\t\t\t\t\t\t\tlayers.Conv2D(32,(3,3),activation='relu',input_shape=(48, 48, 1)),\n",
        "\t\t\t\t\t\t\t\t\tlayers.Conv2D(64,(3,3),activation='relu'),\n",
        "\t\t\t\t\t\t\t\t\tlayers.MaxPooling2D(2,2),\n",
        "\n",
        "\n",
        "\t\t\t\t\t\t\t\t\tlayers.Flatten(),\n",
        "\t\t\t\t\t\t\t\t\tlayers.Dense(64,activation='relu'),\n",
        "\t\t\t\t\t\t\t\t\tlayers.BatchNormalization(),\n",
        "\t\t\t\t\t\t\t\t\tlayers.Dense(32,activation='relu'),\n",
        "\t\t\t\t\t\t\t\t\tlayers.Dropout(0.3),\n",
        "\t\t\t\t\t\t\t\t\tlayers.BatchNormalization(),\n",
        "\t\t\t\t\t\t\t\t\tlayers.Dense(7, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KOOgZVgYJpyj"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "\toptimizer = 'adam',\n",
        "\tloss = 'categorical_crossentropy',\n",
        "\tmetrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "POYfBZ40Jqd7"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "\t  if logs.get('val_accuracy') > 0.90:\n",
        "\t    print('\\n Validation accuracy has reached upto 90% so, stopping further training.')\n",
        "\t    self.model.stop_training = True\n",
        "\n",
        "es = EarlyStopping(patience=3, monitor='val_accuracy', restore_best_weights=True)\n",
        "lr = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, factor=0.5, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e-hc_wOpJspx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "449/449 [==============================] - 121s 270ms/step - loss: 0.2744 - accuracy: 0.9092 - val_loss: 1.9440 - val_accuracy: 0.5093 - lr: 7.8125e-06\n",
            "Epoch 2/50\n",
            "449/449 [==============================] - 119s 264ms/step - loss: 0.2760 - accuracy: 0.9104 - val_loss: 1.9554 - val_accuracy: 0.5107 - lr: 7.8125e-06\n",
            "Epoch 3/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.9114\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "449/449 [==============================] - 119s 265ms/step - loss: 0.2720 - accuracy: 0.9114 - val_loss: 1.9649 - val_accuracy: 0.5111 - lr: 7.8125e-06\n",
            "Epoch 4/50\n",
            "449/449 [==============================] - 119s 264ms/step - loss: 0.2680 - accuracy: 0.9123 - val_loss: 1.9581 - val_accuracy: 0.5102 - lr: 3.9063e-06\n",
            "Epoch 5/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9108\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "449/449 [==============================] - 119s 265ms/step - loss: 0.2707 - accuracy: 0.9108 - val_loss: 1.9672 - val_accuracy: 0.5117 - lr: 3.9063e-06\n",
            "Epoch 6/50\n",
            "449/449 [==============================] - 119s 266ms/step - loss: 0.2651 - accuracy: 0.9132 - val_loss: 1.9645 - val_accuracy: 0.5100 - lr: 1.9531e-06\n",
            "Epoch 7/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9102\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "449/449 [==============================] - 119s 264ms/step - loss: 0.2707 - accuracy: 0.9102 - val_loss: 1.9674 - val_accuracy: 0.5113 - lr: 1.9531e-06\n",
            "Epoch 8/50\n",
            "449/449 [==============================] - 120s 268ms/step - loss: 0.2691 - accuracy: 0.9115 - val_loss: 1.9652 - val_accuracy: 0.5103 - lr: 9.7656e-07\n",
            "Model has been saved.\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_gen, \n",
        "                    validation_data = val_gen, \n",
        "                    epochs = 50, \n",
        "                    verbose = 1, \n",
        "                    callbacks = [es, lr, myCallback()])\n",
        "\n",
        "# Save the trained model to a file\n",
        "model.save('emotion_model.h5')  # Provide the desired file path for saving the model\n",
        "print('Model has been saved.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "chatgpt training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "449/449 [==============================] - 259s 575ms/step - loss: 0.2716 - accuracy: 0.9101 - val_loss: 1.9592 - val_accuracy: 0.5111 - lr: 9.7656e-07\n",
            "Epoch 2/50\n",
            "449/449 [==============================] - 131s 291ms/step - loss: 0.2701 - accuracy: 0.9117 - val_loss: 1.9667 - val_accuracy: 0.5102 - lr: 9.7656e-07\n",
            "Epoch 3/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.9115\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "449/449 [==============================] - 128s 286ms/step - loss: 0.2693 - accuracy: 0.9115 - val_loss: 1.9591 - val_accuracy: 0.5107 - lr: 9.7656e-07\n",
            "Epoch 4/50\n",
            "449/449 [==============================] - 128s 286ms/step - loss: 0.2687 - accuracy: 0.9114 - val_loss: 1.9679 - val_accuracy: 0.5111 - lr: 4.8828e-07\n",
            "Epoch 5/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.9106\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
            "449/449 [==============================] - 131s 292ms/step - loss: 0.2683 - accuracy: 0.9106 - val_loss: 1.9629 - val_accuracy: 0.5111 - lr: 4.8828e-07\n",
            "Epoch 6/50\n",
            "449/449 [==============================] - 128s 285ms/step - loss: 0.2684 - accuracy: 0.9123 - val_loss: 1.9624 - val_accuracy: 0.5110 - lr: 2.4414e-07\n",
            "Epoch 7/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9124\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2679 - accuracy: 0.9124 - val_loss: 1.9626 - val_accuracy: 0.5100 - lr: 2.4414e-07\n",
            "Epoch 8/50\n",
            "449/449 [==============================] - 126s 280ms/step - loss: 0.2678 - accuracy: 0.9111 - val_loss: 1.9628 - val_accuracy: 0.5104 - lr: 1.2207e-07\n",
            "Epoch 9/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.9100\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
            "449/449 [==============================] - 130s 289ms/step - loss: 0.2703 - accuracy: 0.9100 - val_loss: 1.9758 - val_accuracy: 0.5104 - lr: 1.2207e-07\n",
            "Epoch 10/50\n",
            "449/449 [==============================] - 131s 291ms/step - loss: 0.2736 - accuracy: 0.9103 - val_loss: 1.9650 - val_accuracy: 0.5098 - lr: 6.1035e-08\n",
            "Epoch 11/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.9087\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
            "449/449 [==============================] - 131s 292ms/step - loss: 0.2690 - accuracy: 0.9087 - val_loss: 1.9693 - val_accuracy: 0.5102 - lr: 6.1035e-08\n",
            "Epoch 12/50\n",
            "449/449 [==============================] - 131s 291ms/step - loss: 0.2708 - accuracy: 0.9110 - val_loss: 1.9667 - val_accuracy: 0.5106 - lr: 3.0518e-08\n",
            "Epoch 13/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.9086\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2701 - accuracy: 0.9086 - val_loss: 1.9638 - val_accuracy: 0.5107 - lr: 3.0518e-08\n",
            "Epoch 14/50\n",
            "449/449 [==============================] - 129s 288ms/step - loss: 0.2697 - accuracy: 0.9104 - val_loss: 1.9694 - val_accuracy: 0.5103 - lr: 1.5259e-08\n",
            "Epoch 15/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.9106\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
            "449/449 [==============================] - 129s 287ms/step - loss: 0.2713 - accuracy: 0.9106 - val_loss: 1.9647 - val_accuracy: 0.5100 - lr: 1.5259e-08\n",
            "Epoch 16/50\n",
            "449/449 [==============================] - 131s 291ms/step - loss: 0.2672 - accuracy: 0.9126 - val_loss: 1.9656 - val_accuracy: 0.5102 - lr: 7.6294e-09\n",
            "Epoch 17/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.9100\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
            "449/449 [==============================] - 132s 295ms/step - loss: 0.2687 - accuracy: 0.9100 - val_loss: 1.9700 - val_accuracy: 0.5111 - lr: 7.6294e-09\n",
            "Epoch 18/50\n",
            "449/449 [==============================] - 133s 297ms/step - loss: 0.2699 - accuracy: 0.9112 - val_loss: 1.9656 - val_accuracy: 0.5096 - lr: 3.8147e-09\n",
            "Epoch 19/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.9104\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
            "449/449 [==============================] - 138s 308ms/step - loss: 0.2690 - accuracy: 0.9104 - val_loss: 1.9602 - val_accuracy: 0.5114 - lr: 3.8147e-09\n",
            "Epoch 20/50\n",
            "449/449 [==============================] - 132s 295ms/step - loss: 0.2699 - accuracy: 0.9114 - val_loss: 1.9636 - val_accuracy: 0.5104 - lr: 1.9073e-09\n",
            "Epoch 21/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.9104\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
            "449/449 [==============================] - 130s 290ms/step - loss: 0.2692 - accuracy: 0.9104 - val_loss: 1.9696 - val_accuracy: 0.5103 - lr: 1.9073e-09\n",
            "Epoch 22/50\n",
            "449/449 [==============================] - 124s 277ms/step - loss: 0.2678 - accuracy: 0.9114 - val_loss: 1.9632 - val_accuracy: 0.5109 - lr: 9.5367e-10\n",
            "Epoch 23/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.9145\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
            "449/449 [==============================] - 125s 279ms/step - loss: 0.2666 - accuracy: 0.9145 - val_loss: 1.9701 - val_accuracy: 0.5102 - lr: 9.5367e-10\n",
            "Epoch 24/50\n",
            "449/449 [==============================] - 125s 279ms/step - loss: 0.2687 - accuracy: 0.9104 - val_loss: 1.9645 - val_accuracy: 0.5104 - lr: 4.7684e-10\n",
            "Epoch 25/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.9108\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
            "449/449 [==============================] - 125s 278ms/step - loss: 0.2703 - accuracy: 0.9108 - val_loss: 1.9600 - val_accuracy: 0.5088 - lr: 4.7684e-10\n",
            "Epoch 26/50\n",
            "449/449 [==============================] - 129s 287ms/step - loss: 0.2675 - accuracy: 0.9086 - val_loss: 1.9624 - val_accuracy: 0.5106 - lr: 2.3842e-10\n",
            "Epoch 27/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.9101\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
            "449/449 [==============================] - 129s 288ms/step - loss: 0.2682 - accuracy: 0.9101 - val_loss: 1.9703 - val_accuracy: 0.5099 - lr: 2.3842e-10\n",
            "Epoch 28/50\n",
            "449/449 [==============================] - 125s 277ms/step - loss: 0.2693 - accuracy: 0.9112 - val_loss: 1.9610 - val_accuracy: 0.5107 - lr: 1.1921e-10\n",
            "Epoch 29/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.9100\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n",
            "449/449 [==============================] - 126s 281ms/step - loss: 0.2700 - accuracy: 0.9100 - val_loss: 1.9694 - val_accuracy: 0.5118 - lr: 1.1921e-10\n",
            "Epoch 30/50\n",
            "449/449 [==============================] - 129s 286ms/step - loss: 0.2670 - accuracy: 0.9114 - val_loss: 1.9640 - val_accuracy: 0.5117 - lr: 5.9605e-11\n",
            "Epoch 31/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.9102\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n",
            "449/449 [==============================] - 128s 285ms/step - loss: 0.2697 - accuracy: 0.9102 - val_loss: 1.9685 - val_accuracy: 0.5113 - lr: 5.9605e-11\n",
            "Epoch 32/50\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2643 - accuracy: 0.9146 - val_loss: 1.9670 - val_accuracy: 0.5121 - lr: 2.9802e-11\n",
            "Epoch 33/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2681 - accuracy: 0.9120\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2681 - accuracy: 0.9120 - val_loss: 1.9686 - val_accuracy: 0.5110 - lr: 2.9802e-11\n",
            "Epoch 34/50\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2713 - accuracy: 0.9101 - val_loss: 1.9686 - val_accuracy: 0.5106 - lr: 1.4901e-11\n",
            "Epoch 35/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9096\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 7.450580950807417e-12.\n",
            "449/449 [==============================] - 128s 284ms/step - loss: 0.2694 - accuracy: 0.9096 - val_loss: 1.9716 - val_accuracy: 0.5099 - lr: 1.4901e-11\n",
            "Epoch 36/50\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2671 - accuracy: 0.9141 - val_loss: 1.9604 - val_accuracy: 0.5110 - lr: 7.4506e-12\n",
            "Epoch 37/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.9125\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.725290475403709e-12.\n",
            "449/449 [==============================] - 127s 284ms/step - loss: 0.2661 - accuracy: 0.9125 - val_loss: 1.9724 - val_accuracy: 0.5114 - lr: 7.4506e-12\n",
            "Epoch 38/50\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2679 - accuracy: 0.9137 - val_loss: 1.9629 - val_accuracy: 0.5103 - lr: 3.7253e-12\n",
            "Epoch 39/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.9125\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.8626452377018543e-12.\n",
            "449/449 [==============================] - 127s 284ms/step - loss: 0.2686 - accuracy: 0.9125 - val_loss: 1.9664 - val_accuracy: 0.5099 - lr: 3.7253e-12\n",
            "Epoch 40/50\n",
            "449/449 [==============================] - 128s 284ms/step - loss: 0.2671 - accuracy: 0.9127 - val_loss: 1.9678 - val_accuracy: 0.5109 - lr: 1.8626e-12\n",
            "Epoch 41/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.9110\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 9.313226188509272e-13.\n",
            "449/449 [==============================] - 127s 282ms/step - loss: 0.2700 - accuracy: 0.9110 - val_loss: 1.9608 - val_accuracy: 0.5106 - lr: 1.8626e-12\n",
            "Epoch 42/50\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2685 - accuracy: 0.9118 - val_loss: 1.9650 - val_accuracy: 0.5111 - lr: 9.3132e-13\n",
            "Epoch 43/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.9131\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.656613094254636e-13.\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2683 - accuracy: 0.9131 - val_loss: 1.9705 - val_accuracy: 0.5106 - lr: 9.3132e-13\n",
            "Epoch 44/50\n",
            "449/449 [==============================] - 128s 284ms/step - loss: 0.2699 - accuracy: 0.9115 - val_loss: 1.9621 - val_accuracy: 0.5107 - lr: 4.6566e-13\n",
            "Epoch 45/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.9085\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 2.328306547127318e-13.\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2699 - accuracy: 0.9085 - val_loss: 1.9668 - val_accuracy: 0.5114 - lr: 4.6566e-13\n",
            "Epoch 46/50\n",
            "449/449 [==============================] - 127s 282ms/step - loss: 0.2695 - accuracy: 0.9103 - val_loss: 1.9666 - val_accuracy: 0.5104 - lr: 2.3283e-13\n",
            "Epoch 47/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.9115\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.164153273563659e-13.\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2676 - accuracy: 0.9115 - val_loss: 1.9648 - val_accuracy: 0.5104 - lr: 2.3283e-13\n",
            "Epoch 48/50\n",
            "449/449 [==============================] - 127s 283ms/step - loss: 0.2681 - accuracy: 0.9121 - val_loss: 1.9641 - val_accuracy: 0.5109 - lr: 1.1642e-13\n",
            "Epoch 49/50\n",
            "449/449 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.9097\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 5.820766367818295e-14.\n",
            "449/449 [==============================] - 127s 282ms/step - loss: 0.2701 - accuracy: 0.9097 - val_loss: 1.9657 - val_accuracy: 0.5099 - lr: 1.1642e-13\n",
            "Epoch 50/50\n",
            "449/449 [==============================] - 127s 282ms/step - loss: 0.2702 - accuracy: 0.9107 - val_loss: 1.9637 - val_accuracy: 0.5104 - lr: 5.8208e-14\n",
            "Model has been saved.\n"
          ]
        }
      ],
      "source": [
        "# Make changes to the existing code\n",
        "history = model.fit(train_gen, \n",
        "                    validation_data=val_gen, \n",
        "                    epochs=50, \n",
        "                    verbose=1, \n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=50), lr, myCallback()])  # Increase patience to 50\n",
        "model.save('emotion_model.h5')  # Provide the desired file path for saving the model\n",
        "print('Model has been saved.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BGRwwGxdJyeO"
      },
      "outputs": [],
      "source": [
        "def plot_image(img, emoj):\n",
        "\twmin = 256\n",
        "\thmin = 256\n",
        "\n",
        "\temoj = cv2.resize(emoj, (wmin, hmin))\n",
        "\timg = cv2.resize(img, (wmin, hmin))\n",
        "\tcv2.imshow('Images', cv2.hconcat([img, emoj]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DOik_hnrJ1wR"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Load the pre-trained model and classes\n",
        "model = keras.models.load_model('emotion_model.h5')  # Provide the path to your pre-trained model file\n",
        "classes = emotions  # Assuming 'emotions' variable contains the list of emotion classes\n",
        "\n",
        "# Assuming 'plot_image' function is already defined\n",
        "def plot_image(img, emoj):\n",
        "    wmin = 256\n",
        "    hmin = 256\n",
        "    emoj = cv2.resize(emoj, (wmin, hmin))\n",
        "    img = cv2.resize(img, (wmin, hmin))\n",
        "    cv2.imshow('Images', cv2.hconcat([img, emoj]))\n",
        "\n",
        "# Assuming 'train_gen' is your training data generator\n",
        "for img_path in glob('path_to_your_images_directory/*.jpg'):  # Provide the path to the directory containing your images\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "    \n",
        "    for (x, y, w, h) in faces:\n",
        "        gray_face = gray[y:y + h, x:x + w]\n",
        "        gray_face = cv2.resize(gray_face, (48, 48))\n",
        "        gray_face = np.expand_dims(gray_face, axis=-1)\n",
        "        gray_face = np.expand_dims(gray_face, axis=0)\n",
        "\n",
        "        pred = model.predict(gray_face)\n",
        "        idx = pred.argmax(axis=-1)[0]\n",
        "\n",
        "        emoj = cv2.imread(f'emojis/{classes[idx]}.jpg')  # Assuming emoji images are stored in the 'emojis' directory\n",
        "\n",
        "        plot_image(img, emoj)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a43RMFaYJ45F"
      },
      "outputs": [],
      "source": [
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while(True):\n",
        "    ret, img = cap.read()\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "\n",
        "    if len(faces) > 0:\n",
        "        for (x, y, w, h) in faces:\n",
        "            try:\n",
        "                gray_face = cv2.resize(gray[y:y+h, x:x+w], (48, 48))\n",
        "            except Exception as e:\n",
        "                print(str(e))\n",
        "                break\n",
        "\n",
        "            gray_face = np.expand_dims(gray_face, axis=-1)\n",
        "            gray_face = np.expand_dims(gray_face, axis=0)\n",
        "\n",
        "            pred = model.predict(gray_face)\n",
        "            idx = pred.argmax(axis=-1)[0]\n",
        "\n",
        "            emoj_path = f'emojis/{emotions[idx]}.jpg'\n",
        "            emoj = cv2.imread(emoj_path)\n",
        "\n",
        "            if emoj is not None:\n",
        "                emoj = cv2.resize(emoj, (256, 256))\n",
        "                img = cv2.resize(img, (256, 256))\n",
        "                cv2.imshow('Images', cv2.hconcat([img, emoj]))\n",
        "            else:\n",
        "                print(f'Emoji not found for emotion: {emotions[idx]}')\n",
        "\n",
        "    else:\n",
        "        emoj = cv2.imread('NofaceDetected.jpeg')\n",
        "        if emoj is not None:\n",
        "            emoj = cv2.resize(emoj, (256, 256))\n",
        "            img = cv2.resize(img, (256, 256))\n",
        "            cv2.imshow('Images', cv2.hconcat([img, emoj]))\n",
        "        else:\n",
        "            print('No face detected and default emoji not found.')\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Code below with new window of capture and exit button"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "\n",
        "# Function to exit the application\n",
        "def exit_application():\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    root.destroy()\n",
        "\n",
        "# Initialize tkinter\n",
        "root = tk.Tk()\n",
        "root.title(\"Emoji Detector\")\n",
        "\n",
        "# Create a button to exit the application\n",
        "exit_button = ttk.Button(root, text=\"Exit\", command=exit_application)\n",
        "exit_button.pack(pady=10)\n",
        "\n",
        "# Load face cascade classifier\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Open video capture\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, img = cap.read()\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "\n",
        "    if len(faces) > 0:\n",
        "        for (x, y, w, h) in faces:\n",
        "            try:\n",
        "                gray_face = cv2.resize(gray[y:y+h, x:x+w], (48, 48))\n",
        "            except Exception as e:\n",
        "                print(str(e))\n",
        "                break\n",
        "\n",
        "            gray_face = np.expand_dims(gray_face, axis=-1)\n",
        "            gray_face = np.expand_dims(gray_face, axis=0)\n",
        "\n",
        "            pred = model.predict(gray_face)\n",
        "            idx = pred.argmax(axis=-1)[0]\n",
        "\n",
        "            emoj_path = f'emojis/{emotions[idx]}.jpg'\n",
        "            emoj = cv2.imread(emoj_path)\n",
        "\n",
        "            if emoj is not None:\n",
        "                emoj = cv2.resize(emoj, (256, 256))\n",
        "                img = cv2.resize(img, (256, 256))\n",
        "                cv2.imshow('Emoji Detector', cv2.hconcat([img, emoj]))\n",
        "            else:\n",
        "                print(f'Emoji not found for emotion: {emotions[idx]}')\n",
        "\n",
        "    else:\n",
        "        emoj = cv2.imread('NofaceDetected.jpeg')\n",
        "        if emoj is not None:\n",
        "            emoj = cv2.resize(emoj, (256, 256))\n",
        "            img = cv2.resize(img, (256, 256))\n",
        "            cv2.imshow('Emoji Detector', cv2.hconcat([img, emoj]))\n",
        "        else:\n",
        "            print('No face detected and default emoji not found.')\n",
        "\n",
        "    # Check for the exit button press in the tkinter window\n",
        "    root.update()\n",
        "\n",
        "    # Break the loop if the exit button is pressed in the tkinter window\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture and destroy all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Code below to save the image If you press \"C\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Screenshot saved as screenshot_2023-10-28 20-34-24.png\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Screenshot saved as screenshot_2023-10-28 20-34-25.png\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Screenshot saved as screenshot_2023-10-28 20-34-42.png\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Emoji not found for emotion: surprise\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\matrix_operations.cpp:67: error: (-215:Assertion failed) src[i].dims <= 2 && src[i].rows == src[0].rows && src[i].type() == src[0].type() in function 'cv::hconcat'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\omadi\\Desktop\\emogen\\emogen.ipynb Cell 19\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/omadi/Desktop/emogen/emogen.ipynb#X21sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m# Check for the capture button press ('C' key)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/omadi/Desktop/emogen/emogen.ipynb#X21sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/omadi/Desktop/emogen/emogen.ipynb#X21sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         capture_screenshot()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/omadi/Desktop/emogen/emogen.ipynb#X21sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# Release the camera and close all windows\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/omadi/Desktop/emogen/emogen.ipynb#X21sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n",
            "\u001b[1;32mc:\\Users\\omadi\\Desktop\\emogen\\emogen.ipynb Cell 19\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/omadi/Desktop/emogen/emogen.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m timestamp \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39mH-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/omadi/Desktop/emogen/emogen.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m screenshot_filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mscreenshot_\u001b[39m\u001b[39m{\u001b[39;00mtimestamp\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/omadi/Desktop/emogen/emogen.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(screenshot_filename, cv2\u001b[39m.\u001b[39;49mhconcat([img, emoj]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/omadi/Desktop/emogen/emogen.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mScreenshot saved as \u001b[39m\u001b[39m{\u001b[39;00mscreenshot_filename\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\matrix_operations.cpp:67: error: (-215:Assertion failed) src[i].dims <= 2 && src[i].rows == src[0].rows && src[i].type() == src[0].type() in function 'cv::hconcat'\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "# Function to capture and save a screenshot\n",
        "def capture_screenshot():\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
        "    screenshot_filename = f\"screenshot_{timestamp}.png\"\n",
        "    cv2.imwrite(screenshot_filename, cv2.hconcat([img, emoj]))\n",
        "    print(f'Screenshot saved as {screenshot_filename}')\n",
        "\n",
        "# Initialize the camera\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Load face cascade classifier\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "while True:\n",
        "    ret, img = cap.read()\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "\n",
        "    if len(faces) > 0:\n",
        "        for (x, y, w, h) in faces:\n",
        "            try:\n",
        "                gray_face = cv2.resize(gray[y:y+h, x:x+w], (48, 48))\n",
        "            except Exception as e:\n",
        "                print(str(e))\n",
        "                break\n",
        "\n",
        "            gray_face = np.expand_dims(gray_face, axis=-1)\n",
        "            gray_face = np.expand_dims(gray_face, axis=0)\n",
        "\n",
        "            pred = model.predict(gray_face)\n",
        "            idx = pred.argmax(axis=-1)[0]\n",
        "\n",
        "            emoj_path = f'emojis/{emotions[idx]}.jpg'\n",
        "            emoj = cv2.imread(emoj_path)\n",
        "\n",
        "            if emoj is not None:\n",
        "                emoj = cv2.resize(emoj, (256, 256))\n",
        "                img = cv2.resize(img, (256, 256))\n",
        "                cv2.imshow('Emoji Detector', cv2.hconcat([img, emoj]))\n",
        "            else:\n",
        "                print(f'Emoji not found for emotion: {emotions[idx]}')\n",
        "\n",
        "    else:\n",
        "        emoj = cv2.imread('NofaceDetected.jpeg')\n",
        "        if emoj is not None:\n",
        "            emoj = cv2.resize(emoj, (256, 256))\n",
        "            img = cv2.resize(img, (256, 256))\n",
        "            cv2.imshow('Emoji Detector', cv2.hconcat([img, emoj]))\n",
        "\n",
        "    # Check for the exit button press\n",
        "    key = cv2.waitKey(10)\n",
        "\n",
        "    if key & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    # Check for the capture button press ('C' key)\n",
        "    if key & 0xFF == ord('c'):\n",
        "        capture_screenshot()\n",
        "\n",
        "# Release the camera and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
